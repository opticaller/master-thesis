\chapter {Shadow Memory}

The shadow-memory model used by AddressSanitizer is very simple. A process'
entire memory space gets mapped to a fraction of it. For instance, with an $1:8$
compression, one continuous eigth of the addressable memory space gets reserved.
8 bytes of memory in the address space then correspond to one byte in this
map. The value of the byte encodes which of the 8 bytes are allocated. We'd like
to point out that for this thesis, the compression ratio between shadow memory
and main memory is a power of two. Though it may be technically possible to use
other alignments, we find no reason to explore this area, LLVM doesn't support
those alignments and instrumented code can be more efficient with powers of two.

AddressSanitizer instruments LLVM Bitcode so that, when allocating memory, the
corresponding fraction of addresses get marked as allocated in the shadow
memory. The code is also instrumented so that, before every instruction which
operates on memory, assertions are inserted to check their correctness before
actually performing them.

We propose a different encoding into the same shadow-map scheme. Whereas
AddressSanitizer encodes into this byte how many of the corresponding $n$
($n = 8$ in the previous case) original bytes have been allocated, we propose
encoding a plugin-instance id instead. This way, we lose granularity, as a
single $n$-byte block is either ok to read or write, or not. But it allows us to
perform a quick check on whether the read is OK or not. The proposition is
primarily a means of protection and isolation, not a debugging tool. Other
encodings are of course possible, as well as different tools.

For shadow-map specfics, we would like to point out AddressSantizer as the
authoritive implementation of this shadow-memory technique. We have been able to
reproduce the essential memory mapping in AddressSanitizer, with simliar
overhead, but their implementation in Clang is way more mature. Their
paper[ref] also provide a good benchmark over performance hits imposed by the
technique.


\section {Whitelist/Blacklist differences}

TODO: Fill me? Does ASan really Blacklist edges? We whitelist allocated memory,
not poison zones around them.


\section {Shadow Compression}

This single-level shadow map makes a $1:1$ mapping impossible, the shadow memory
would occupy the entire memory space and leave no room even for the running
code. $1:2$ mappings would reserve half of the address space and so forth. On
64-bit systems this is not a major issue, as the address space are many orders
of magnitude larger than the physical memory available. 32-bit systems however
have significantly limited address space.

The compression ratio between real memory and shadow memory directly affects
performance. If an aligned memory access is smaller than the compression ratio
then only a single check in the shadow is needed. This is crucial to be able to
provide access to basic types, such as \texttt{int}, \texttt{float} and
\texttt{double}, with acceptable overhead.

\subsection {Granularity}

As memory-access is granted based on memory blocks and not individual bytes,
memory must be handled in multiples of the compression ratio and be aligned to
the compression ratio boundary. For a $1:8$ ratio, that means all memory
allocation must occur in multiples of $8$ and its base address be a multiple of
$8$. This should, of course, be invisible to the plugin and sufficient memory
should be allocated to accomodate the requested allocation size aligned to the
proper boundary, as well as allocating any remaining space in the final block.


\section {Memory Management}

Any memory usable by the plugin directly (without external function calls) needs
to, regardless of how it was allocated, be marked as owned by the plugin
instance before it can being used. After the memory is no longer accessible to
the plugin instance it needs to be unmarked.

Heap-allocated memory is a resource which needs to be tracked and validated when
sent as a parameter to free or realloc etc. A plugin instance should not be able
to free random memory addresses, as this can cause serious memory corruption. As
the host needs to shut down a plugin instance gracefully it needs to know of
which heap-memory segments were allocated to that instance, so they can be
safely returned to avoid memory leaks.

\subsection {Memory Alignment}

Alignment + Access Size <= Compression Ratio => One check.

\subsection {Heap Allocation}

Mark: malloc, related functions and API functions allocating memory for the
plugin instance.

Unmark: free, realloc, related functions, API functions for freeing memory.

Allocation plus freeing. Alignments, block sizes.

\subsection {Stack Allocation}

Mark: Stack allocation, local variables

Unmark: End of scope

At first glance, a simple solution to the stack-allocation problem would be to,
once and for all, mark each entire stack space upon thread creation to belong to
a plugin instance. Apart from forcing a 1:1 mapping between plugin instances and
threads, this has serious security implications as well. The plugin should only
be able to access the memory on the stack used for variables. It should not be
able to otherwise alter the execution stack in any manner. If such alteration
were possible from a plugin it could, intentionally or not, smash the stack,
introduce buffer overruns and quite easily execute return-to-libc[ref-phrack]
attacks to break out of its own sandbox and run uninstrumented code.


