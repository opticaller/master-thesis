\chapter {Memory-Error Detection}

Memory-error detection often works partly by, in some manner, tracking what
memory is addressible and what is not. Then upon trying to access, or modify
memory improperly an error is detected and reported back, and depending on the
design, the memory-error detector potentially aborts execution. Aborting
execution on erroneous memory accesses echoes the requirements of memory
isolation between plugin instances.

The tools differ in what errors they detect and, how likely they're detected and
how they can be used. Some, such as Valgrind [link-to-paper-here], use runtime
techniques, such as dynamic recompilation and run binaries out of the box.
Others require that a program is compiled in a certain way, such as specifying
additional compile-time flags. Inherently Valgrind can be used to detect memory
errors in a program to which the source code or build environment is not readily
available.

To protect the host and other plugins running inside the same process from
having their heaps and/or stacks read or modified, memory accesses between
plugins and the host (and other programs) must be verified to be correct in one
way or another. Memory protection available on most modern platforms, often
reinforced by hardware support, operate on a process level. All memory within a
process is naturally shared with every thread of execution, all access-control
restrictions are implemented on a per-process level. Some thread
implementations[ref-thread-userspace(multirefs)] are even implemented inside
user space(/user mode?) making the kernel completely unaware of their
existence at all.

Memory-error detectors are able to track different things, and detect different
kinds of memory errors. Inherently, they store different amounts of data, and
are able to track more than whether a byte has been properly allocated or not.
Valgrind for instance, tracks the validity, or \emph{defined-ness}, of every bit
in addition to the byte's addressability. If we can instead encode which plugin
instance owns a certain piece of memory, we should be able to identify when a
plugin instance attempts to access memory which it does not own by using
techniques similar to those used by memory-error detectors.

To be relevant to our problem however, errors need to be able to be detected at
the point of occurance, so that a plugin can be aborted when trying to do
something it's not allowed to do, and not after. The main difference between our
solution and what memory-error detectors provide out of the box is that the
error detectors work on a per-process basis.


\section {Shadow Memory}

Many different tools use shadow memory to store metadata corresponding to the
actual memory. That is, memory addresses are mapped to a shadow value which
stores some data related to that range of addresses. The tools differ in
granularity. For instance, Valgrind detects errors on a bit level, while
AddressSanitizer detects errors on a per-byte level. The tools also replace or
hook memory-related functions including \texttt{malloc} and \texttt{free} to be
able to track valid memory blocks. That is, when memory is allocated, the
corresponding shadow memory must be marked as accessible, and marked as
inaccessible when not allocated, to not introduce false positives or negatives.

What's actually encoded in the shadow memory can be arbitrary. For this thesis
we'll consider a model in which the plugin instance is encoded into the shadow
memory. This way we can detect not only if the memory is correct on a process
level, but rather if it can be accessed by the plugin instance. This part will
be covered later in Chapter [ref-shadow].

How the shadow memory is compressed, stored and accessed has impacts both on
performance and feasibility. Valgrind for instance, stores more than a byte of
information for every memory byte available on the system, something impossible
without any compression. AddressSanitizer however uses flat continous shadow
memory with completely different performance characteristics while still able to
to detect many common memory errors.


\section {Valgrind/Memcheck}

Memcheck is a memory-error detector implemented with the binary-instrumentation
framework Valgrind[ref-bit-precision].
Memcheck uses dynamic binary instrumentation to allow the
program to be checked on runtime.
Inherently, programs do not have to be recompiled to be error checked by
Memcheck.
All parts of a client program are instrumented by Memcheck, including
dynamically-linked libraries, which allows for total coverage.
Even of code which is not under control by the user.

Memcheck tracks addressability and validity of every byte of memory used by the
program.
It tracks all heap blocks allocated with \texttt{malloc()}, \texttt{new} and 
\texttt{new[]} and detect bad or repeated frees of heap blocks.
By tracking heap blocks, it can also report memory leaks at program termination.
It also supplements functions like \texttt{strcpy()} and \texttt{memcpy()} with
additional checks, verifying that their arguments do not overlap.

Memcheck operates with great precision.
As of their 2005 paper, it's the only tool which they are aware of that detect
errors with bit, and not byte, precision.
Every byte, including registers, is shadowed with a mask of which bits are
defined.
When performing instructions on one or more operands, the validity masks are
combined into a new one in accordance with the instruction.
A shift instruction for instance would shift the validity bits as well.
Then when jumps depending on or output of a value which outcome isn't completely
defined occur, an error is reported.

Valgrind's dynamic binary instrumentation along with Memcheck's instrumented
checks unfortunately add significant overhead.
A program running under nulgrind, a do-nothing tool for Valgrind, is reported
to have a geometric-mean slowdown factor of $4.9$ for a number of tested
programs.
Memcheck also add further overhead, and the corresponding mean reported is here
$25.7$.
In their $2007$ paper, they report a slowdown of $22.2$ with moderate memory
usage[ref-grind-shadow]
Though this is fast enough for usage in large applications, as have been done
with success in several large-scale open-source projects, this significant
overhead may discourage continuous usage of the tool.

For code with tough real-time constraints, such as Reason, this overhead
unfortunately makes Valgrind/Memcheck impossible to use or very restricted in
usage.
Especially in combination with the additional logging and asserts inserted into
debug builds.

\subsection {Shadow Memory}

Memcheck implements a similar basic shadow-memory data structure to several
other shadow-memory tools.
It however implements several novel optimizations that speed up common cases.
The shadow memory is compressed into two levels, one `primary map' which maps
$64k$ blocks to `secondary maps'.
The secondary maps include metadata on a per-byte level.
Initially all primary-map entries point to a `no-access distinguished secondary
map', which is marked as inaccessible and never modified.
usage of Valgrind at all.
The secondary map contains addressability and validity bits.
As partially defined bytes are uncommon, Memcheck tracks them in a sparse
third-level table.
This allows for storing only two bits per byte in the secondary map.
These bits can indicate that the byte is either not accessible, undefined,
completely defined or partially defined.
Only when a byte is partially defined its validity bits must be examined.




\section {AddressSanitizer}

AddressSanitizer is a simple compile-time solution which instruments the
\texttt{load} and \texttt{store} instructions of a program to preceed them with
checks to validate the instruction operand.
It's a tool used to detect out-of-bounds accesses to memory by poisoning
(marking as invalid) so-called `red-zones' around allocated memory.
Its paper reports an average slowdown of 2x, which allows it to be used in
realtime in Chromium for instance, where it has found several hundred
bugs[ref-asan].

Detecting out-of-bounds accesses to memory includes insertion of red-zones
between stack- and globally-allocated memory.
This prevents memory accesses to stack-allocated variables to `spill over' to
adjacent variables.
Stack-allocated red-zones are unpoisoned just before the function returns, as
memory allocated on the stack is freed by the stack pointer decreasing.
Were this not done, other function calls' stack-allocated variables might be
part of old calls' red-zones.
In this case they would still be poisoned and, though correct, the memory
accesses would generate errors.

\begin{figure}[ht]
\begin{lstlisting}[language=C]
// Before AddressSanitizer
*address = ...;  // or: ... = *address;
\end{lstlisting}

\begin{lstlisting}[language=C]
// After AddressSanitizer
if (IsPoisoned(address)) {
    ReportError(address, kAccessSize, kIsWrite);
}
*address = ...;  // or: ... = *address;
\end{lstlisting}
\caption{Simplified description [ref-asan-desc] of the AddressSanitizer
instrumentation of dereferences of memory though reads or writes.}
\end{figure}

<asan-desc: http://code.google.com/p/address-sanitizer/wiki/AddressSanitizerAlgorithm>

\noindent Memory accesses to random locations will not be found by the
instrumented code itself before the point of occurence, but the runtime library
will catch memory errors signals from the kernel and generate an error message
including a stack trace.
Any invalid accesses to memory not covered by the red-zone, which are undetected
by the operating system will not be detected by AddressSanitizer either.
Stack memory for instance isn't explicitly requested from the operating system
explicitly.
Instead a continuous stack region is reserved when a thread is created, and
though variables on the stack haven't been allocated yet, the entire stack
region is accessible.
This makes AddressSanitizer's original implementation unable to detect
use-after-return bugs, illustrated in Figure [ref-figure], though an
experimental feature addresses this limitation[ref-use-after-return].
We suspect that this feature might be implemented by poisoning the stack
variables before the callee function returns, and unpoisoned when new memory
is allocated in its place on the stack.
Random invalid accesses to memory which is not allocated by the running code,
yet might have been allocated memory will not be able to be detected by the
instrumented code itself.

<use-after-return: http://code.google.com/p/address-sanitizer/wiki/ExampleUseAfterReturn>

\begin{figure}[ht]
\begin{lstlisting}[language=C]
#include <stdio.h>

int *f()
{
    int n = 123456;
    return &n;
}

int main ()
{
    int *x = f();
    printf("%d\n", *x); // use of stack-allocated memory after return
    return 0;
}
\end{lstlisting}
\caption{Use after return, a bug not detectable in the original AddressSanitizer
implementation.}
\end{figure}

After being freed, heap memory segments are stored in a quarantine
area, and the shadow bytes are marked as inaccessible for as long as it is in
the quarantine.
By default this quarantine is $256 MB$.
Any accesses to memory which is quarantined will detect usage-after-free bugs
based on dangling pointers erroneously kept alive, or prematurely
freeing blocks.

\subsection {Shadow Memory}

AddressSanitizer's simple single-level shadow map is what allows it to keep its
performance and its instrumented code relatively small.
By default AddressSanitizer reserves $1/8th$ by default of the memory space for
shadow memory, but it does not allocate it.
Every $8$ bytes then corresponds to $1$ byte.
To translate from address to shadow memory the address is divided by $8$
(through a shift by $3$, for performance), and then the offset, or base address,
of the shadow memory is added.

A continuous fraction of the whole memory space is mapped up, but not reserved
using \texttt{mmap}.
On read the corresponding page gets loaded by the OS and initialized to $0$.
For AddressSanitizer, this value $0$ means that all corresponding memory bytes
are ok to access.
This is the common path.

The less common path requires further examination of the shadow byte.
When the shadow byte isn't $0$, then the shadow byte encodes either which of
these than of these ($8$ by default) bytes are accessible, or that none of them
are.
In order to prevent instrumented code from reading or modifying the the shadow
memory itself, the shadow memory pages corresponding to the memory bytes where
the shadow memory recides are marked as inaccessible so that access to them
trigger page faults which are caught by the runtime, which then aborts.


\section {Per-Instance Address Spaces}

For a broader coverage of of the process and for flavor, we'd like to mention
another even more coarse-grained error-detection technique along with its flaws
which was considered before AddressSanitizer was recommended to us, and why the
solution was ultimately discarded even before we heard of AddressSanitizer.

Placing each plugin instance's stack and heap into its own continuous address
space allows for a single coarse-grained check against start and end address. By
allocating a continous segment as a power of two, this can be done efficiently
by masking the memory address to get its base address.

On 32-bit platforms virtual address space is limited however, and if there's no
good estimate on how much memory a plugin instance will use, the instance might
either have too much space allocated and the host's total address space
might run out when using too many extensions. Also, if the address space for an
extension runs out, it can't allocate more memory.

Worst of all is possibly the false sense of security this solution provides when
attempting to protect against malicious plugins, or malicious input to them
through bugs. As the stack recides inside the instance's address space, it means
that all of the stack can be written to. However, the only part a a plugin
instance should be able to modify freely are local stack variables. Other data
such as return addresses need to be preserved in order to preserve control flow.

Failure to protect return addresses can lead to a buffer overflow causing the
plugin to return to uninstrumented code by smashing the stack. Existing software
vulnerable to such exploits are quite commonly found. The attack itself is well
explained by  [phrack-pseudonym, ref]. A program which \emph{intentionally}
exposes itself to such vulnerabilities or performs such attacks upon itself is
of course even easier to write.
