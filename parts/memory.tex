\chapter {Memory-Error Detection}

Memory-error detection often works partly by, in some manner, tracking what
memory is addressible and what is not. Then upon trying to access, or modify
memory improperly an error is detected and reported back, and depending on the
design, the memory-error detector potentially aborts execution. Aborting
execution on erroneous memory accesses echoes the requirements of memory
isolation between plugin instances.

The tools differ in what errors they detect and, how likely they're detected and
how they can be used. Some, such as Valgrind [link-to-paper-here], use runtime
techniques, such as dynamic recompilation and run binaries out of the box.
Others require that a program is compiled in a certain way, such as specifying
additional compile-time flags. Inherently Valgrind can be used to detect memory
errors in a program to which the source code or build environment is not readily
available.

To protect the host and other plugins running inside the same process from
having their heaps and/or stacks read or modified, memory accesses between
plugins and the host (and other programs) must be verified to be correct in one
way or another. Memory protection available on most modern platforms, often
reinforced by hardware support, operate on a process level. All memory within a
process is naturally shared with every thread of execution, all access-control
restrictions are implemented on a per-process level. Some thread
implementations[ref-thread-userspace(multirefs)] are even implemented inside
user space(/user mode?) making the kernel completely unaware of their
existence at all.

Memory-error detectors are able to track different things, and detect different
kinds of memory errors. Inherently, they store different amounts of data, and
are able to track more than whether a byte has been properly allocated or not.
Valgrind for instance, tracks the validity, or \emph{defined-ness}, of every bit
in addition to the byte's addressability. If we can instead encode which plugin
instance owns a certain piece of memory, we should be able to identify when a
plugin instance attempts to access memory which it does not own by using
techniques similar to those used by memory-error detectors.

To be relevant to our problem however, errors need to be able to be detected at
the point of occurance, so that a plugin can be aborted when trying to do
something it's not allowed to do, and not after. The main difference between our
solution and what memory-error detectors provide out of the box is that the
error detectors work on a per-process basis.


\section {Shadow Memory}

Many different tools use shadow memory to store metadata corresponding to the
actual memory. That is, memory addresses are mapped to a shadow value which
stores some data related to that range of addresses. The tools differ in
granularity. For instance, Valgrind detects errors on a bit level, while
AddressSanitizer detects errors on a per-byte level. The tools also replace or
hook memory-related functions including \texttt{malloc} and \texttt{free} to be
able to track valid memory blocks. That is, when memory is allocated, the
corresponding shadow memory must be marked as accessible, and marked as
inaccessible when not allocated, to not introduce false positives or negatives.

What's actually encoded in the shadow memory can be arbitrary. For this thesis
we'll consider a model in which the plugin instance is encoded into the shadow
memory. This way we can detect not only if the memory is correct on a process
level, but rather if it can be accessed by the plugin instance. This part will
be covered later in Chapter [ref-shadow].

How the shadow memory is compressed, stored and accessed has impacts both on
performance and feasibility. Valgrind for instance, stores more than a byte of
information for every memory byte available on the system, something impossible
without any compression. AddressSanitizer however uses flat continous shadow
memory with completely different performance characteristics while still able to
to detect many common memory errors.


\section {Valgrind}

Overhead.
Valgrind for instance, tracks the \emph{defined-ness} of every bit and, as of
their $2007$ paper, stores $10$ bytes in total per $8$ bytes of addressable
memory.

\subsection {Hooks}

\subsection {Characteristsics}

\subsection {Shadow Map}


\section {AddressSanitizer}

Stuff.

\subsection {Hooks}

\subsection {Characteristsics}

\subsection {Shadow Map}


\section {Per-Instance Address Spaces}

For a broader coverage of of the process and for flavor, we'd like to mention
another even more coarse-grained error-detection technique along with its flaws
which was considered before AddressSanitizer was recommended to us, and why the
solution was ultimately discarded even before we heard of AddressSanitizer.

Placing each plugin instance's stack and heap into its own continuous address
space allows for a single coarse-grained check against start and end address. By
allocating a continous segment as a power of two, this can be done efficiently
by masking the memory address to get its base address.

On 32-bit platforms virtual address space is limited however, and if there's no
good estimate on how much memory a plugin instance will use, the instance might
either have too much space allocated and the host's total address space
might run out when using too many extensions. Also, if the address space for an
extension runs out, it can't allocate more memory.

Worst of all is possibly the false sense of security this solution imposes when
attempting to protect against malicious plugins, or malicious input to them
through bugs. As the stack recides inside the instance's address space, it means
that all of the stack can be written to. However, the only part a a plugin
instance should be able to modify freely are local stack variables. Other data
such as return addresses need to be preserved in order to preserve control flow.

Failure to protect return addresses can lead to a buffer overflow causing the
plugin to return to uninstrumented code by smashing the stack. Existing software
vulnerable to such exploits are quite commonly found. The attack itself is well
explained by  [phrack-pseudonym, ref]. A program which \emph{intentionally}
exposes itself to such vulnerabilities or performs such an attack upon itself is
even easier to write.
